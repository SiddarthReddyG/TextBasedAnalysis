{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8624b4d",
   "metadata": {},
   "source": [
    "## ASSIGNMENT 4\n",
    "## SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265beb8",
   "metadata": {},
   "source": [
    "### IMPORT PANDAS AND READ .CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51ab8f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Image_Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Elk Grove, CA</td>\n",
       "      <td>Reviewed Aug. 11, 2017</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Starbucks employees that gotten out of hand. T...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>Larry</td>\n",
       "      <td>Livermore, CA</td>\n",
       "      <td>Reviewed Sept. 4, 2012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I go regularly to the Starbucks at 223 South V...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>Mari</td>\n",
       "      <td>Claremont, CA</td>\n",
       "      <td>Reviewed July 5, 2009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I asked for a tall coffee that would be poured...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>margaret</td>\n",
       "      <td>Tacoma, WA</td>\n",
       "      <td>Reviewed March 31, 2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Has anyone been annoyed with the service at St...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Linda</td>\n",
       "      <td>Fountain Hills, AZ</td>\n",
       "      <td>Reviewed June 1, 2021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I contacted Starbucks customer service to ask ...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Cathi</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Reviewed Dec. 19, 2018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My sweetheart and I went into our neighborhood...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Francois</td>\n",
       "      <td>San Marcos, CA</td>\n",
       "      <td>Reviewed Jan. 18, 2019</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Aside from great drinks and good food the serv...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>Daniel</td>\n",
       "      <td>Loveland, CO</td>\n",
       "      <td>Reviewed Dec. 24, 2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Review Text</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>VICTORIA</td>\n",
       "      <td>Salt Lake City, UT</td>\n",
       "      <td>Reviewed Oct. 12, 2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I love Starbucks!!! I frequent Starbucks every...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Sharon</td>\n",
       "      <td>Grand Rapids, MI</td>\n",
       "      <td>Reviewed Oct. 1, 2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I have been a loyal customer of Starbucks for ...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name            location                     Date  Rating  \\\n",
       "366      Brad       Elk Grove, CA   Reviewed Aug. 11, 2017     3.0   \n",
       "639     Larry       Livermore, CA   Reviewed Sept. 4, 2012     2.0   \n",
       "781      Mari       Claremont, CA    Reviewed July 5, 2009     NaN   \n",
       "438  margaret          Tacoma, WA  Reviewed March 31, 2016     1.0   \n",
       "121     Linda  Fountain Hills, AZ    Reviewed June 1, 2021     1.0   \n",
       "215     Cathi              Canada   Reviewed Dec. 19, 2018     1.0   \n",
       "210  Francois      San Marcos, CA   Reviewed Jan. 18, 2019     5.0   \n",
       "810    Daniel        Loveland, CO   Reviewed Dec. 24, 2008     NaN   \n",
       "466  VICTORIA  Salt Lake City, UT   Reviewed Oct. 12, 2015     1.0   \n",
       "170    Sharon    Grand Rapids, MI    Reviewed Oct. 1, 2019     1.0   \n",
       "\n",
       "                                                Review    Image_Links  \n",
       "366  Starbucks employees that gotten out of hand. T...  ['No Images']  \n",
       "639  I go regularly to the Starbucks at 223 South V...  ['No Images']  \n",
       "781  I asked for a tall coffee that would be poured...  ['No Images']  \n",
       "438  Has anyone been annoyed with the service at St...  ['No Images']  \n",
       "121  I contacted Starbucks customer service to ask ...  ['No Images']  \n",
       "215  My sweetheart and I went into our neighborhood...  ['No Images']  \n",
       "210  Aside from great drinks and good food the serv...  ['No Images']  \n",
       "810                                     No Review Text  ['No Images']  \n",
       "466  I love Starbucks!!! I frequent Starbucks every...  ['No Images']  \n",
       "170  I have been a loyal customer of Starbucks for ...  ['No Images']  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas package and reading .csv file\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.read_csv( 'reviews_data.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3110f8",
   "metadata": {},
   "source": [
    "### NLTK AND OPINION LEXICON "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf86876",
   "metadata": {},
   "source": [
    "The Natural Language Toolkit is used to access the Opinion Lexicon, which is a lexicon of positive and negative opinion words or sentiment words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8deb722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in opinion lexicon 6789\n",
      "Examples of positive words in opinion lexicon ['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation']\n",
      "Examples of negative words in opinion lexicon ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /Users/sid/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing ntlk package \n",
    "\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "nltk.download('opinion_lexicon')\n",
    "from nltk.corpus import opinion_lexicon                     # using opinion lexicon dataset from nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print('Total number of words in opinion lexicon', len(opinion_lexicon.words()))\n",
    "print('Examples of positive words in opinion lexicon',      # printing 10 positive opinion lexicons\n",
    "      opinion_lexicon.positive()[:10])\n",
    "print('Examples of negative words in opinion lexicon',      # printing 10 negative opinion lexicons\n",
    "      opinion_lexicon.negative()[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1ec892",
   "metadata": {},
   "source": [
    "### DICTIONARY FOR SCORING REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e2c5880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Let's create a dictionary which we can use it for scoring our review text\n",
    "\n",
    "nltk.download('punkt')\n",
    "df.rename(columns={\"Review\": \"text\"}, inplace=True)\n",
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    " \n",
    "# Adding the positive words to the dictionary\n",
    "\n",
    "for word in opinion_lexicon.positive():\n",
    "        word_dict[word] = pos_score\n",
    "      \n",
    "# Adding the negative words to the dictionary\n",
    "\n",
    "for word in opinion_lexicon.negative():\n",
    "        word_dict[word] = neg_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d59ba",
   "metadata": {},
   "source": [
    "### BING_LIU_SCORE FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3ad3f",
   "metadata": {},
   "source": [
    "To group a dataframe df by unique values in the 'overall' column and calculate the mean of the 'Bing_Liu_Score' column for each group to give avg sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6ad40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bing_liu_score function \n",
    "\n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0\n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "    for word in bag_of_words:\n",
    "        if word in word_dict:\n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe48d3e",
   "metadata": {},
   "source": [
    "### REPLACING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "486730e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling empty claues with 'no review'\n",
    "\n",
    "df['text'].fillna('no review', inplace=True)\n",
    "df['Bing_Liu_Score'] = df['text'].apply(bing_liu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582b0d9f",
   "metadata": {},
   "source": [
    "### HEAD METHOD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f523dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>text</th>\n",
       "      <th>Bing_Liu_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Amber and LaDonna at the Starbucks on Southwes...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>** at the Starbucks by the fire station on 436...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I just wanted to go out of my way to recognize...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Me and my friend were at Starbucks and my card...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I’m on this kick of drinking 5 cups of warm wa...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>We had to correct them on our order 3 times. T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I have tried Starbucks several different times...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Starbucks near me just launched new fall foods...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I ordered online for the Reisterstown Rd, St T...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Staff at the Smythe St. Superstore location in...</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                               text  Bing_Liu_Score\n",
       "0     5.0  Amber and LaDonna at the Starbucks on Southwes...               5\n",
       "1     5.0  ** at the Starbucks by the fire station on 436...               9\n",
       "2     5.0  I just wanted to go out of my way to recognize...               3\n",
       "3     5.0  Me and my friend were at Starbucks and my card...               6\n",
       "4     5.0  I’m on this kick of drinking 5 cups of warm wa...              10\n",
       "5     1.0  We had to correct them on our order 3 times. T...               1\n",
       "6     1.0  I have tried Starbucks several different times...              -1\n",
       "7     1.0  Starbucks near me just launched new fall foods...               1\n",
       "8     1.0  I ordered online for the Reisterstown Rd, St T...              -3\n",
       "9     1.0  Staff at the Smythe St. Superstore location in...              -5"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using head() on dataframe\n",
    "\n",
    "df[['Rating',\"text\", 'Bing_Liu_Score']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e79f05",
   "metadata": {},
   "source": [
    "### GROUPBY OVERALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe21246d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bing_Liu_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-0.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>-0.070707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>2.358974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>4.012048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bing_Liu_Score\n",
       "Rating                \n",
       "1.0          -0.682927\n",
       "2.0          -0.070707\n",
       "3.0           1.424242\n",
       "4.0           2.358974\n",
       "5.0           4.012048"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grouping by unique values \n",
    "\n",
    "df.groupby('Rating').agg({'Bing_Liu_Score':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11c000",
   "metadata": {},
   "source": [
    "## APPLYING F-1 SCORING FOR BING-LIU ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f7cd3",
   "metadata": {},
   "source": [
    "we applied f-1 score to evaluate performance of algorithm------edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "710105de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.5401984518579771\n"
     ]
    }
   ],
   "source": [
    "# Apply bing_liu_score function to calculate sentiment scores for each review\n",
    "df['Bing_Liu_Score'] = df['text'].apply(bing_liu_score)\n",
    "\n",
    "# Define true labels based on the 'Rating' column\n",
    "df['True_Labels'] = df['Rating'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutral')\n",
    "\n",
    "# Define predicted scores based on the 'Bing_Liu_Score' column\n",
    "df['Predicted_Scores'] = df['Bing_Liu_Score'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(df['True_Labels'], df['Predicted_Scores'], average='weighted')\n",
    "\n",
    "print(\"F1-score:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ddfded",
   "metadata": {},
   "source": [
    "## VADER LEXICON SCORING ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9e8a3",
   "metadata": {},
   "source": [
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically used to perform analysis on sentiments expressed in social media. It assigns sentiment scores to text documents, indicating the positivity, negativity, or neutrality of the sentiment expressed in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a8c6af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/sid/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating                                             Review  VADER_Score\n",
      "0     5.0  Amber and LaDonna at the Starbucks on Southwes...       0.8991\n",
      "1     5.0  ** at the Starbucks by the fire station on 436...       0.7766\n",
      "2     5.0  I just wanted to go out of my way to recognize...       0.5242\n",
      "3     5.0  Me and my friend were at Starbucks and my card...       0.9698\n",
      "4     5.0  I’m on this kick of drinking 5 cups of warm wa...       0.9793\n",
      "5     1.0  We had to correct them on our order 3 times. T...      -0.7269\n",
      "6     1.0  I have tried Starbucks several different times...      -0.8963\n",
      "7     1.0  Starbucks near me just launched new fall foods...       0.8994\n",
      "8     1.0  I ordered online for the Reisterstown Rd, St T...      -0.8316\n",
      "9     1.0  Staff at the Smythe St. Superstore location in...      -0.7912\n",
      "        VADER_Score\n",
      "Rating             \n",
      "1.0       -0.149688\n",
      "2.0       -0.020645\n",
      "3.0        0.159991\n",
      "4.0        0.642367\n",
      "5.0        0.724286\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import pandas as pd \n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "df = pd.read_csv('reviews_data.csv')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_score(text):\n",
    "    sentiment_score = sid.polarity_scores(text)['compound']\n",
    "    return sentiment_score\n",
    "\n",
    "df['Review'].fillna('no review', inplace=True)\n",
    "\n",
    "df['VADER_Score'] = df['Review'].apply(vader_score)\n",
    "\n",
    "print(df[['Rating', 'Review', 'VADER_Score']].head(10))\n",
    "\n",
    "print(df.groupby('Rating').agg({'VADER_Score': 'mean'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de328f80",
   "metadata": {},
   "source": [
    "## APPLYING F-1 SCORING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb867fe6",
   "metadata": {},
   "source": [
    "we used F-1 score algorithm to evaluate the performance of a model in predicting two classes: positive and negative (or true and false). It combines the precision and recall of a model into a single metric, providing a balance between these two aspects of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ee15798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.49143257430718185\n"
     ]
    }
   ],
   "source": [
    "df['VADER_Score'] = df['Review'].apply(vader_score)\n",
    "\n",
    "df['True_Labels'] = df['Rating'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutral')\n",
    "\n",
    "df['Predicted_Labels'] = df['VADER_Score'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "\n",
    "f1 = f1_score(df['True_Labels'], df['Predicted_Labels'], average='weighted')\n",
    "\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f1e39",
   "metadata": {},
   "source": [
    "## TEXTBLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d342d119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating                                             Review  TextBlob_Score\n",
      "0     5.0  Amber and LaDonna at the Starbucks on Southwes...        0.340816\n",
      "1     5.0  ** at the Starbucks by the fire station on 436...        0.289394\n",
      "2     5.0  I just wanted to go out of my way to recognize...       -0.060714\n",
      "3     5.0  Me and my friend were at Starbucks and my card...        0.263750\n",
      "4     5.0  I’m on this kick of drinking 5 cups of warm wa...        0.356905\n",
      "5     1.0  We had to correct them on our order 3 times. T...        0.008929\n",
      "6     1.0  I have tried Starbucks several different times...        0.000000\n",
      "7     1.0  Starbucks near me just launched new fall foods...        0.133144\n",
      "8     1.0  I ordered online for the Reisterstown Rd, St T...       -0.500000\n",
      "9     1.0  Staff at the Smythe St. Superstore location in...       -0.173810\n",
      "        TextBlob_Score\n",
      "Rating                \n",
      "1.0          -0.029953\n",
      "2.0           0.022190\n",
      "3.0           0.112247\n",
      "4.0           0.244469\n",
      "5.0           0.319508\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df = pd.read_csv('reviews_data.csv')\n",
    "\n",
    "def textblob_score(text):\n",
    "    sentiment_score = TextBlob(text).sentiment.polarity\n",
    "    return sentiment_score\n",
    "\n",
    "df['Review'].fillna('no review', inplace=True)\n",
    "\n",
    "df['TextBlob_Score'] = df['Review'].apply(textblob_score)\n",
    "\n",
    "print(df[['Rating', 'Review', 'TextBlob_Score']].head(10))\n",
    "\n",
    "print(df.groupby('Rating').agg({'TextBlob_Score': 'mean'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f5256",
   "metadata": {},
   "source": [
    "## APPLYING F-1 SCORING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f93cdbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.5395528343601881\n"
     ]
    }
   ],
   "source": [
    "df['True_Labels'] = df['Rating'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutral')\n",
    "\n",
    "df['Predicted_Labels'] = df['TextBlob_Score'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "\n",
    "f1 = f1_score(df['True_Labels'], df['Predicted_Labels'], average='weighted')\n",
    "\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "885e26ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting senticnet\n",
      "  Downloading senticnet-1.6-py3-none-any.whl (51.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: senticnet\n",
      "Successfully installed senticnet-1.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!pip install senticnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79014916",
   "metadata": {},
   "source": [
    "## SENTICNET SCORING ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0323dc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating                                             Review  SenticNet_Score\n",
      "0     5.0  Amber and LaDonna at the Starbucks on Southwes...         0.024383\n",
      "1     5.0  ** at the Starbucks by the fire station on 436...         0.035695\n",
      "2     5.0  I just wanted to go out of my way to recognize...         0.069542\n",
      "3     5.0  Me and my friend were at Starbucks and my card...         0.057500\n",
      "4     5.0  I’m on this kick of drinking 5 cups of warm wa...         0.082932\n",
      "5     1.0  We had to correct them on our order 3 times. T...        -0.036397\n",
      "6     1.0  I have tried Starbucks several different times...        -0.001422\n",
      "7     1.0  Starbucks near me just launched new fall foods...         0.066921\n",
      "8     1.0  I ordered online for the Reisterstown Rd, St T...        -0.005109\n",
      "9     1.0  Staff at the Smythe St. Superstore location in...         0.005837\n",
      "        SenticNet_Score\n",
      "Rating                 \n",
      "1.0            0.019291\n",
      "2.0            0.021642\n",
      "3.0            0.034656\n",
      "4.0            0.050713\n",
      "5.0            0.058446\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from senticnet.senticnet import SenticNet\n",
    "\n",
    "df = pd.read_csv('reviews_data.csv')\n",
    "\n",
    "sn = SenticNet()\n",
    "def senticnet_score(text):\n",
    "    words = text.split()\n",
    "    sentiment_scores = [float(sn.polarity_value(word.lower())) if word.lower() in sn.data else 0 for word in words]\n",
    "    if sentiment_scores:\n",
    "        sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "    else:\n",
    "        sentiment_score = 0  \n",
    "    return sentiment_score\n",
    "\n",
    "df['Review'].fillna('no review', inplace=True)\n",
    "\n",
    "df['SenticNet_Score'] = df['Review'].apply(senticnet_score)\n",
    "\n",
    "print(df[['Rating', 'Review', 'SenticNet_Score']].head(10))\n",
    "\n",
    "print(df.groupby('Rating').agg({'SenticNet_Score': 'mean'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2373637",
   "metadata": {},
   "source": [
    "## F-1 SCORING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ba7312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.29808810480714026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df['True_Labels'] = df['Rating'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutral')\n",
    "\n",
    "df['Predicted_Labels'] = df['SenticNet_Score'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "\n",
    "f1 = f1_score(df['True_Labels'], df['Predicted_Labels'], average='weighted')\n",
    "\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5b5b2",
   "metadata": {},
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869febf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
