{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8624b4d",
   "metadata": {},
   "source": [
    "## ASSIGNMENT 4\n",
    "## SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265beb8",
   "metadata": {},
   "source": [
    "### IMPORT PANDAS AND READ .CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51ab8f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>Image_Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Kip</td>\n",
       "      <td>Vallejo, CA</td>\n",
       "      <td>Reviewed June 27, 2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I want to share with you a story about how Sta...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>Erik</td>\n",
       "      <td>Valley Village, CA</td>\n",
       "      <td>Reviewed Nov. 5, 2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEMANDED TIPS FROM ME, THEN MADE ME WAIT UNTIL...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Raymond</td>\n",
       "      <td>Thornton, CO</td>\n",
       "      <td>Reviewed June 23, 2017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I recently have had problems with the customer...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Linda</td>\n",
       "      <td>Valencia, CA</td>\n",
       "      <td>Reviewed June 9, 2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>On Monday morning, 6/7/10, I arrived at Starbu...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>Margo</td>\n",
       "      <td>Charlottesville, WI</td>\n",
       "      <td>Reviewed Aug. 20, 2016</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I enjoy Starbucks coffee, food, and other beve...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Shelley</td>\n",
       "      <td>Stockton, CA</td>\n",
       "      <td>Reviewed May 17, 2018</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This store (Fremont &amp; Wilson Starbucks in Cali...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>J M</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Reviewed Dec. 21, 2012</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I don't shop online at Starbucks because whene...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>Laura</td>\n",
       "      <td>Fresno, CA</td>\n",
       "      <td>Reviewed Dec. 20, 2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>My husband disabled has brain damage as well a...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>Katie</td>\n",
       "      <td>Escondido, CA</td>\n",
       "      <td>Reviewed March 4, 2009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Review Text</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Sharon</td>\n",
       "      <td>Fairbanks, AK</td>\n",
       "      <td>Reviewed Nov. 1, 2019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I ordered two to go coffee boxes at least 10 d...</td>\n",
       "      <td>['No Images']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name             location                    Date  Rating  \\\n",
       "620      Kip          Vallejo, CA  Reviewed June 27, 2013     1.0   \n",
       "847     Erik   Valley Village, CA   Reviewed Nov. 5, 2004     NaN   \n",
       "377  Raymond         Thornton, CO  Reviewed June 23, 2017     1.0   \n",
       "742    Linda         Valencia, CA   Reviewed June 9, 2010     NaN   \n",
       "411    Margo  Charlottesville, WI  Reviewed Aug. 20, 2016     3.0   \n",
       "245  Shelley         Stockton, CA   Reviewed May 17, 2018     5.0   \n",
       "632      J M          Seattle, WA  Reviewed Dec. 21, 2012     2.0   \n",
       "544    Laura           Fresno, CA  Reviewed Dec. 20, 2014     1.0   \n",
       "798    Katie        Escondido, CA  Reviewed March 4, 2009     NaN   \n",
       "165   Sharon        Fairbanks, AK   Reviewed Nov. 1, 2019     1.0   \n",
       "\n",
       "                                                Review    Image_Links  \n",
       "620  I want to share with you a story about how Sta...  ['No Images']  \n",
       "847  DEMANDED TIPS FROM ME, THEN MADE ME WAIT UNTIL...  ['No Images']  \n",
       "377  I recently have had problems with the customer...  ['No Images']  \n",
       "742  On Monday morning, 6/7/10, I arrived at Starbu...  ['No Images']  \n",
       "411  I enjoy Starbucks coffee, food, and other beve...  ['No Images']  \n",
       "245  This store (Fremont & Wilson Starbucks in Cali...  ['No Images']  \n",
       "632  I don't shop online at Starbucks because whene...  ['No Images']  \n",
       "544  My husband disabled has brain damage as well a...  ['No Images']  \n",
       "798                                     No Review Text  ['No Images']  \n",
       "165  I ordered two to go coffee boxes at least 10 d...  ['No Images']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas package and reading .csv file\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.read_csv( 'reviews_data.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3110f8",
   "metadata": {},
   "source": [
    "### NLTK AND OPINION LEXICON "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf86876",
   "metadata": {},
   "source": [
    "The Natural Language Toolkit is used to access the Opinion Lexicon, which is a lexicon of positive and negative opinion words or sentiment words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8deb722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in opinion lexicon 6789\n",
      "Examples of positive words in opinion lexicon ['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation']\n",
      "Examples of negative words in opinion lexicon ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /Users/sid/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing ntlk package \n",
    "\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "nltk.download('opinion_lexicon')\n",
    "from nltk.corpus import opinion_lexicon                     # using opinion lexicon dataset from nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print('Total number of words in opinion lexicon', len(opinion_lexicon.words()))\n",
    "print('Examples of positive words in opinion lexicon',      # printing 10 positive opinion lexicons\n",
    "      opinion_lexicon.positive()[:10])\n",
    "print('Examples of negative words in opinion lexicon',      # printing 10 negative opinion lexicons\n",
    "      opinion_lexicon.negative()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1ec892",
   "metadata": {},
   "source": [
    "### DICTIONARY FOR SCORING REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e2c5880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sid/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Let's create a dictionary which we can use it for scoring our review text\n",
    "\n",
    "nltk.download('punkt')\n",
    "df.rename(columns={\"Review\": \"text\"}, inplace=True)\n",
    "pos_score = 1\n",
    "neg_score = -1\n",
    "word_dict = {}\n",
    " \n",
    "# Adding the positive words to the dictionary\n",
    "\n",
    "for word in opinion_lexicon.positive():\n",
    "        word_dict[word] = pos_score\n",
    "      \n",
    "# Adding the negative words to the dictionary\n",
    "\n",
    "for word in opinion_lexicon.negative():\n",
    "        word_dict[word] = neg_scorez\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d59ba",
   "metadata": {},
   "source": [
    "### BING_LIU_SCORE FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3ad3f",
   "metadata": {},
   "source": [
    "To group a dataframe df by unique values in the 'overall' column and calculate the mean of the 'Bing_Liu_Score' column for each group to give avg sentiment score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ad40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bing_liu_score function \n",
    "\n",
    "def bing_liu_score(text):\n",
    "    sentiment_score = 0\n",
    "    bag_of_words = word_tokenize(text.lower())\n",
    "    for word in bag_of_words:\n",
    "        if word in word_dict:\n",
    "            sentiment_score += word_dict[word]\n",
    "    return sentiment_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe48d3e",
   "metadata": {},
   "source": [
    "### REPLACING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "486730e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling empty claues with 'no review'\n",
    "\n",
    "df['text'].fillna('no review', inplace=True)\n",
    "df['Bing_Liu_Score'] = df['text'].apply(bing_liu_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582b0d9f",
   "metadata": {},
   "source": [
    "### HEAD METHOD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f523dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>text</th>\n",
       "      <th>Bing_Liu_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Amber and LaDonna at the Starbucks on Southwes...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>** at the Starbucks by the fire station on 436...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I just wanted to go out of my way to recognize...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Me and my friend were at Starbucks and my card...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I’m on this kick of drinking 5 cups of warm wa...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>We had to correct them on our order 3 times. T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I have tried Starbucks several different times...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Starbucks near me just launched new fall foods...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I ordered online for the Reisterstown Rd, St T...</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Staff at the Smythe St. Superstore location in...</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                               text  Bing_Liu_Score\n",
       "0     5.0  Amber and LaDonna at the Starbucks on Southwes...               5\n",
       "1     5.0  ** at the Starbucks by the fire station on 436...               9\n",
       "2     5.0  I just wanted to go out of my way to recognize...               3\n",
       "3     5.0  Me and my friend were at Starbucks and my card...               6\n",
       "4     5.0  I’m on this kick of drinking 5 cups of warm wa...              10\n",
       "5     1.0  We had to correct them on our order 3 times. T...               1\n",
       "6     1.0  I have tried Starbucks several different times...              -1\n",
       "7     1.0  Starbucks near me just launched new fall foods...               1\n",
       "8     1.0  I ordered online for the Reisterstown Rd, St T...              -3\n",
       "9     1.0  Staff at the Smythe St. Superstore location in...              -5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using head() on dataframe\n",
    "\n",
    "df[['Rating',\"text\", 'Bing_Liu_Score']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e79f05",
   "metadata": {},
   "source": [
    "### GROUPBY OVERALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe21246d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bing_Liu_Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>-0.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>-0.070707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>2.358974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>4.012048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bing_Liu_Score\n",
       "Rating                \n",
       "1.0          -0.682927\n",
       "2.0          -0.070707\n",
       "3.0           1.424242\n",
       "4.0           2.358974\n",
       "5.0           4.012048"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grouping by unique values \n",
    "\n",
    "df.groupby('Rating').agg({'Bing_Liu_Score':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11c000",
   "metadata": {},
   "source": [
    "## APPLYING F-1 SCORING FOR BING-LIU ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424f7cd3",
   "metadata": {},
   "source": [
    "We applied f1 scoring to evaluate performance of algorithm using bing liu algrithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3dbfc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710105de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bing liu F1-score: 0.5401984518579771\n"
     ]
    }
   ],
   "source": [
    "# Apply bing_liu_score function to calculate sentiment scores for each review\n",
    "df['Bing_Liu_Score'] = df['text'].apply(bing_liu_score)\n",
    "\n",
    "# Define true labels based on the 'Rating' column\n",
    "df['True_Labels'] = df['Rating'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutral')\n",
    "\n",
    "# Define predicted scores based on the 'Bing_Liu_Score' column\n",
    "df['Predicted_Scores'] = df['Bing_Liu_Score'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(df['True_Labels'], df['Predicted_Scores'], average='weighted')\n",
    "\n",
    "print(\" Bing liu F1-score:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ddfded",
   "metadata": {},
   "source": [
    "## VADER LEXICON SCORING ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9e8a3",
   "metadata": {},
   "source": [
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically used to perform analysis on sentiments expressed in social media. It assigns sentiment scores to text documents, indicating the positivity, negativity, or neutrality of the sentiment expressed in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a8c6af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/sid/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating                                             Review  VADER_Score\n",
      "0     5.0  Amber and LaDonna at the Starbucks on Southwes...       0.8991\n",
      "1     5.0  ** at the Starbucks by the fire station on 436...       0.7766\n",
      "2     5.0  I just wanted to go out of my way to recognize...       0.5242\n",
      "3     5.0  Me and my friend were at Starbucks and my card...       0.9698\n",
      "4     5.0  I’m on this kick of drinking 5 cups of warm wa...       0.9793\n",
      "5     1.0  We had to correct them on our order 3 times. T...      -0.7269\n",
      "6     1.0  I have tried Starbucks several different times...      -0.8963\n",
      "7     1.0  Starbucks near me just launched new fall foods...       0.8994\n",
      "8     1.0  I ordered online for the Reisterstown Rd, St T...      -0.8316\n",
      "9     1.0  Staff at the Smythe St. Superstore location in...      -0.7912\n",
      "        VADER_Score\n",
      "Rating             \n",
      "1.0       -0.149688\n",
      "2.0       -0.020645\n",
      "3.0        0.159991\n",
      "4.0        0.642367\n",
      "5.0        0.724286\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import pandas as pd \n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "df = pd.read_csv('reviews_data.csv')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_score(text):\n",
    "    sentiment_score = sid.polarity_scores(text)['compound']\n",
    "    return sentiment_score\n",
    "\n",
    "df['Review'].fillna('no review', inplace=True)\n",
    "\n",
    "df['VADER_Score'] = df['Review'].apply(vader_score)\n",
    "\n",
    "print(df[['Rating', 'Review', 'VADER_Score']].head(10))\n",
    "\n",
    "print(df.groupby('Rating').agg({'VADER_Score': 'mean'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de328f80",
   "metadata": {},
   "source": [
    "##  F-1 SCORING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb867fe6",
   "metadata": {},
   "source": [
    "we used F-1 score algorithm to evaluate the performance of a model in predicting two classes: positive and negative (or true and false). It combines the precision and recall of a model into a single metric, providing a balance between these two aspects of performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee15798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader Lexicon F1-score: 0.49143257430718185\n"
     ]
    }
   ],
   "source": [
    "df['VADER_Score'] = df['Review'].apply(vader_score)\n",
    "\n",
    "df['True_Labels'] = df['Rating'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutral')\n",
    "\n",
    "df['Predicted_Labels'] = df['VADER_Score'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "\n",
    "f1 = f1_score(df['True_Labels'], df['Predicted_Labels'], average='weighted')\n",
    "\n",
    "print(\"Vader Lexicon F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f1e39",
   "metadata": {},
   "source": [
    "## TEXTBLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d342d119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating                                             Review  TextBlob_Score\n",
      "0     5.0  Amber and LaDonna at the Starbucks on Southwes...        0.340816\n",
      "1     5.0  ** at the Starbucks by the fire station on 436...        0.289394\n",
      "2     5.0  I just wanted to go out of my way to recognize...       -0.060714\n",
      "3     5.0  Me and my friend were at Starbucks and my card...        0.263750\n",
      "4     5.0  I’m on this kick of drinking 5 cups of warm wa...        0.356905\n",
      "5     1.0  We had to correct them on our order 3 times. T...        0.008929\n",
      "6     1.0  I have tried Starbucks several different times...        0.000000\n",
      "7     1.0  Starbucks near me just launched new fall foods...        0.133144\n",
      "8     1.0  I ordered online for the Reisterstown Rd, St T...       -0.500000\n",
      "9     1.0  Staff at the Smythe St. Superstore location in...       -0.173810\n",
      "        TextBlob_Score\n",
      "Rating                \n",
      "1.0          -0.029953\n",
      "2.0           0.022190\n",
      "3.0           0.112247\n",
      "4.0           0.244469\n",
      "5.0           0.319508\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df = pd.read_csv('reviews_data.csv')\n",
    "\n",
    "def textblob_score(text):\n",
    "    sentiment_score = TextBlob(text).sentiment.polarity\n",
    "    return sentiment_score\n",
    "\n",
    "df['Review'].fillna('no review', inplace=True)\n",
    "\n",
    "df['TextBlob_Score'] = df['Review'].apply(textblob_score)\n",
    "\n",
    "print(df[['Rating', 'Review', 'TextBlob_Score']].head(10))\n",
    "\n",
    "print(df.groupby('Rating').agg({'TextBlob_Score': 'mean'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f5256",
   "metadata": {},
   "source": [
    "## APPLYING F-1 SCORING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f93cdbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textblob F1-score: 0.5395528343601881\n"
     ]
    }
   ],
   "source": [
    "df['True_Labels'] = df['Rating'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutral')\n",
    "\n",
    "df['Predicted_Labels'] = df['TextBlob_Score'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "\n",
    "f1 = f1_score(df['True_Labels'], df['Predicted_Labels'], average='weighted')\n",
    "\n",
    "print(\"Textblob F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79014916",
   "metadata": {},
   "source": [
    "## SENTICNET SCORING ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0323dc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rating                                             Review  SenticNet_Score\n",
      "0     5.0  Amber and LaDonna at the Starbucks on Southwes...         0.024383\n",
      "1     5.0  ** at the Starbucks by the fire station on 436...         0.035695\n",
      "2     5.0  I just wanted to go out of my way to recognize...         0.069542\n",
      "3     5.0  Me and my friend were at Starbucks and my card...         0.057500\n",
      "4     5.0  I’m on this kick of drinking 5 cups of warm wa...         0.082932\n",
      "5     1.0  We had to correct them on our order 3 times. T...        -0.036397\n",
      "6     1.0  I have tried Starbucks several different times...        -0.001422\n",
      "7     1.0  Starbucks near me just launched new fall foods...         0.066921\n",
      "8     1.0  I ordered online for the Reisterstown Rd, St T...        -0.005109\n",
      "9     1.0  Staff at the Smythe St. Superstore location in...         0.005837\n",
      "        SenticNet_Score\n",
      "Rating                 \n",
      "1.0            0.019291\n",
      "2.0            0.021642\n",
      "3.0            0.034656\n",
      "4.0            0.050713\n",
      "5.0            0.058446\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from senticnet.senticnet import SenticNet\n",
    "\n",
    "df = pd.read_csv('reviews_data.csv')\n",
    "\n",
    "sn = SenticNet()\n",
    "def senticnet_score(text):\n",
    "    words = text.split()\n",
    "    sentiment_scores = [float(sn.polarity_value(word.lower())) if word.lower() in sn.data else 0 for word in words]\n",
    "    if sentiment_scores:\n",
    "        sentiment_score = sum(sentiment_scores) / len(sentiment_scores)\n",
    "    else:\n",
    "        sentiment_score = 0  \n",
    "    return sentiment_score\n",
    "\n",
    "df['Review'].fillna('no review', inplace=True)\n",
    "\n",
    "df['SenticNet_Score'] = df['Review'].apply(senticnet_score)\n",
    "\n",
    "print(df[['Rating', 'Review', 'SenticNet_Score']].head(10))\n",
    "\n",
    "print(df.groupby('Rating').agg({'SenticNet_Score': 'mean'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2373637",
   "metadata": {},
   "source": [
    "## F-1 SCORING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ba7312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senticnet F1 Score: 0.29808810480714026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "df['True_Labels'] = df['Rating'].apply(lambda x: 'positive' if x >= 4 else 'negative' if x <= 2 else 'neutral')\n",
    "\n",
    "df['Predicted_Labels'] = df['SenticNet_Score'].apply(lambda x: 'positive' if x > 0 else 'negative' if x < 0 else 'neutral')\n",
    "\n",
    "f1 = f1_score(df['True_Labels'], df['Predicted_Labels'], average='weighted')\n",
    "\n",
    "print(\"Senticnet F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5b5b2",
   "metadata": {},
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f2604",
   "metadata": {},
   "source": [
    "After using algorithms like textblob, bing liu, senticnet and vander lexicon it is clear that senticnet performs the least with score of 0.29 and textblob and bing liu score with highest f1 score i.e. around 0.50. So it is clear that the alogrithms with highest are better than senticnet and vader lexicon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
